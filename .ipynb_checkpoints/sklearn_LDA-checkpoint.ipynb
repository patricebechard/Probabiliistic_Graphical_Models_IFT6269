{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Get the 20 news groups data \"\"\"\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(shuffle=True, random_state=1, subset=\"train\", \n",
    "                                      remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(shuffle=True, random_state=1, subset=\"test\",\n",
    "                                remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "\"\"\" Prepare input for sklearn (counts) \"\"\"\n",
    "n_features = 2000\n",
    "vectorizer = CountVectorizer(max_features=n_features, stop_words=\"english\")\n",
    "\n",
    "# Word counts per document matrix (input for sklearn)\n",
    "W_counts = vectorizer.fit_transform(newsgroups.data)\n",
    "\n",
    "# Keep track of vocabulary to visualize top words of each topic\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "god people jesus say does believe think don know just bible christian\n",
      "Topic 2:\n",
      "cx ah w7 chz lk c_ hz uw t7 ck mv 34u\n",
      "Topic 3:\n",
      "game gun team year games season hockey play guns win firearms teams\n",
      "Topic 4:\n",
      "mail price thanks new sale interested offer sell used looking email monitor\n",
      "Topic 5:\n",
      "just like know don ve got think good didn ll really time\n",
      "Topic 6:\n",
      "good year players 55 player average years league points better excellent stats\n",
      "Topic 7:\n",
      "file output entry program section files line int rules use null number\n",
      "Topic 8:\n",
      "key encryption chip use keys clipper security privacy public law information government\n",
      "Topic 9:\n",
      "drive scsi card disk bit hard drives use bus does controller pc\n",
      "Topic 10:\n",
      "gm apr dos la pt vs 16 mm pm ma 23 1993\n",
      "Topic 11:\n",
      "window windows use using problem application screen display program set server widget\n",
      "Topic 12:\n",
      "people don think government just like right make want know money say\n",
      "Topic 13:\n",
      "mr people think israel don president know did israeli stephanopoulos said going\n",
      "Topic 14:\n",
      "00 50 10 000 15 20 40 new cover 30 25 art\n",
      "Topic 15:\n",
      "edu com available ftp image version pub file graphics files list mail\n",
      "Topic 16:\n",
      "don db car like time use just right good used power way\n",
      "Topic 17:\n",
      "space research nasa 1993 center data university information science earth launch new\n",
      "Topic 18:\n",
      "armenian people armenians turkish said jews war turkey women government killed armenia\n",
      "Topic 19:\n",
      "10 11 12 25 14 16 13 18 17 15 19 24\n",
      "Topic 20:\n",
      "ax max g9v b8f a86 pl 145 1d9 0t 1t giz bhj\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def visualizeTopics(model, id2word, n_top_words=12):\n",
    "    for i, topic in enumerate(model.components_):\n",
    "        print \"Topic {}:\".format(i+1)\n",
    "        print \" \".join([id2word[j] \n",
    "                        for j in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "n_topics = 20\n",
    "lda_sklearn = LatentDirichletAllocation(n_topics=n_topics, \n",
    "                                        learning_method=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train on training set\n",
    "lda_sklearn.fit(W_counts)\n",
    "\n",
    "# Visualize learnt topics\n",
    "visualizeTopics(lda_sklearn, vocabulary)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(shuffle=True, random_state=1, subset=\"test\",\n",
    "                                remove=(\"headers\", \"footers\", \"quotes\"), categories=cats)\n",
    "\n",
    "# Test on test set\n",
    "lda_sklearn.fit(W_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
