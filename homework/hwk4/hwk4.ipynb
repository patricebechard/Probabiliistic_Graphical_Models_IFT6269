{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor : Patrice Bechard BECP30119404\\nIFT6269 - Probabilistic Graphical Models\\nHomework 3 - Hidden Markov Model Implementation\\nNovember 21th, 2017\\n'"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Author : Patrice Bechard BECP30119404\n",
    "IFT6269 - Probabilistic Graphical Models\n",
    "Homework 3 - Hidden Markov Model Implementation\n",
    "November 21th, 2017\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as col\n",
    "import sys\n",
    "from matplotlib.patches import Ellipse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining initial prob, transition matrix,\n",
    "# means and covariance matrices of clusters (given)\n",
    "\n",
    "np.random.seed(6269)\n",
    "\n",
    "MEAN = np.array([[-2.0344,  4.1726],\n",
    "                 [ 3.9779,  3.7735],\n",
    "                 [ 3.8007, -3.7972],\n",
    "                 [-3.0620, -3.5345]])\n",
    "\n",
    "COV = np.array([[[2.9044,  0.2066],\n",
    "                 [0.2066,  2.7562]],\n",
    "                [[0.2104,  0.2904],\n",
    "                 [0.2904, 12.2392]],\n",
    "                [[0.9213,  0.0574],\n",
    "                 [0.0574,  1.8660]],\n",
    "                [[6.2414,  6.0502],\n",
    "                 [6.0502,  6.1825]]])\n",
    "\n",
    "PI = np.ones(MEAN.shape[0]) / MEAN.shape[0]\n",
    "\n",
    "TRANSIT_MATRIX = np.array([[1/2, 1/6, 1/6, 1/6],\n",
    "                           [1/6, 1/2, 1/6, 1/6],\n",
    "                           [1/6, 1/6, 1/2, 1/6],\n",
    "                           [1/6, 1/6, 1/6, 1/2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    \"\"\"K-means algorithm for clustering unlabeled data\"\"\"\n",
    "    \n",
    "    def __init__(self, n_states, train_data, init=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_classes : integer\n",
    "            number K of clusters to separate data\n",
    "        n_dims : integer\n",
    "            number of dimensions for the data\n",
    "        train_data : array-like, shape = [n_examples, n_dims]\n",
    "            data used to train the clustering algorithm\n",
    "        initializing : boolean\n",
    "            parameter is True if the algorithm is used to initialize cluster\n",
    "            means for another clustering algorithm\n",
    "        \"\"\"\n",
    "        self.n_states = n_states\n",
    "        self.n_pts = train_data.shape[0]\n",
    "        self.n_dims = train_data.shape[1]\n",
    "        self.train_data = train_data\n",
    "        self.trained = False\n",
    "        self.init = init\n",
    "        \n",
    "        self._init_cluster_means()         #initializing self.means randomly\n",
    "        self.z = np.zeros(self.n_pts).astype('int')\n",
    "        \n",
    "    def train(self, n_iter=None):\n",
    "        \"\"\"\n",
    "        Training the algorithm until convergence of objective function\n",
    "        or for a certain number of iterations\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_iter : int (or None)\n",
    "            Number of iterations to train the K-means algorithm.\n",
    "            If it is None, we train the k-means algorithm\n",
    "            until convergence.            \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        z : array-like, shape = [n_examples,n_classes]\n",
    "            array of onehot vectors indicating to which cluster each data\n",
    "            point is assigned\n",
    "        mean : array-like, shape = [n_classes,n_dims]\n",
    "            array containing the cluster mean for each class\n",
    "        \"\"\"\n",
    "        \n",
    "        if n_iter is None:\n",
    "            \n",
    "            # initial values for convergence condition\n",
    "            old_val = 1e9                       \n",
    "            new_val = 1e8       \n",
    "            \n",
    "            while np.abs(old_val - new_val) > 0.0001:    #convergence criterion\n",
    "                #E step\n",
    "                for i in range(self.n_pts):\n",
    "                    dist = np.sum(np.abs(self.train_data[i] - self.mean), axis=1)\n",
    "                    self.z[i] = np.argmin(dist)\n",
    "                    \n",
    "                #M step\n",
    "                update_mean = np.zeros_like(self.mean)\n",
    "                for i in range(self.n_pts):\n",
    "                    update_mean[self.z[i]] += self.train_data[i]\n",
    "                     \n",
    "                self.mean = np.divide(update_mean.T, np.bincount(self.z)).T\n",
    "            \n",
    "                old_val = new_val\n",
    "                new_val = self._compute_objective()\n",
    "        else:\n",
    "            for i in range(n_iter):\n",
    "                #E step\n",
    "                for i in range(self.n_pts):\n",
    "                    dist = np.sum(np.abs(self.train_data[i] - self.mean), axis=1)\n",
    "                    self.z[i] = np.argmin(dist)\n",
    "                    \n",
    "                #M step\n",
    "                update_mean = np.zeros_like(self.mean)\n",
    "                for i in range(self.n_pts):\n",
    "                    update_mean[self.z[i]] += self.train_data[i]\n",
    "                     \n",
    "                self.mean = np.divide(update_mean.T, np.bincount(self.z)).T       \n",
    "        \n",
    "        self.trained = True\n",
    "        \n",
    "        if self.init:                #algorithm used to initialize values for another algorithm\n",
    "            return self.z, self.mean\n",
    "    \n",
    "    def show_clusters(self, tag=None):\n",
    "        \n",
    "        if self.trained:\n",
    "            \"\"\"Show data, cluster means and cluster assignments\"\"\" \n",
    "            colors = ['r','g','b','y']\n",
    "            datacolor = []\n",
    "            datalabels = np.argmax(self.z,axis=1)\n",
    "            for i in range(len(datalabels)):\n",
    "                datacolor.append(colors[datalabels[i]])\n",
    "            objective = self._compute_objective()\n",
    "            \n",
    "            plt.scatter(self.train_data[:,0], self.train_data[:,1],alpha=0.3,marker='.',c=datacolor)\n",
    "            plt.scatter(self.mean[:,0], self.mean[:,1],marker='X',s=150,facecolor=colors, edgecolors='k',lw=2)\n",
    "            plt.xlabel('feature 1')\n",
    "            plt.ylabel('feature 2')\n",
    "            plt.title('Final position of cluster means with associated clusters (J=%.2f)'%objective)\n",
    "            if tag is not None:\n",
    "                plt.savefig('latex/figures/final_kmeans_%02d.png'%tag)\n",
    "            print('Value of objective function at end of convergence : %.2f'%objective)\n",
    "\n",
    "        else:\n",
    "            \"\"\"only show data points and randomly set cluster means\"\"\"\n",
    "            plt.scatter(self.train_data[:,0], self.train_data[:,1],marker='.', alpha=0.3)\n",
    "            plt.scatter(self.mean[:,0], self.mean[:,1],marker='X',s=150, edgecolors='k',lw=2)\n",
    "            plt.xlabel('feature 1')\n",
    "            plt.ylabel('feature 2')\n",
    "            plt.title('Initial cluster means position')\n",
    "            if tag is not None:\n",
    "                plt.savefig('latex/figures/init_kmeans_%02d.png'%tag) \n",
    "\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    def _init_cluster_means(self):\n",
    "        \"\"\"Randomly initializing cluster means within domain where data spreads\"\"\"\n",
    "        self.mean = np.zeros((self.n_states, self.n_dims))\n",
    "        x_span = np.max(self.train_data[:,0])-np.min(self.train_data[:,0])\n",
    "        y_span = np.max(self.train_data[:,1])-np.min(self.train_data[:,1])\n",
    "        \n",
    "        for i in range(self.n_states):\n",
    "            x_comp = x_span * np.random.random() + np.min(self.train_data[:,0])\n",
    "            y_comp = y_span * np.random.random() + np.min(self.train_data[:,1])\n",
    "\n",
    "            self.mean[i] = np.array([x_comp,y_comp])\n",
    "        \n",
    "    def _compute_objective(self):\n",
    "        \"\"\"Computes objective function which we try to minimize\"\"\"\n",
    "        objective = 0\n",
    "        for i in range(self.n_pts):\n",
    "            objective += np.sum(np.abs(self.train_data[i] - \\\n",
    "                                       self.mean[self.z[i]])**2)\n",
    "        return objective\n",
    "            \n",
    "    def log_likelihood(self, data):\n",
    "        \"\"\"Computes objective function which we try to minimize\"\"\"\n",
    "        objective = 0\n",
    "        n_pts = data.shape[0]\n",
    "        \n",
    "        #E step\n",
    "        for i in range(n_pts):\n",
    "            dist = np.sum(np.abs(data[i] - self.mean), axis=1)\n",
    "            objective += np.sum(np.abs(data[i] - self.mean[argmin(dist)])**2)\n",
    "            \n",
    "        return objective / n_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    \"\"\"Gaussian mixture model using the EM algorithm to cluster data for unsupervised learning\"\"\"\n",
    "    \n",
    "    def __init__(self, n_states, train_data, cov_type):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_classes : integer\n",
    "            number K of clusters to separate data\n",
    "        n_dims : integer\n",
    "            number of dimensions for the data\n",
    "        train_data : array-like, shape = [n_examples, n_dims]\n",
    "            data used to train the clustering algorithm\n",
    "        cov_type : string\n",
    "            defines the type of covariance matrix used to fit the data.\n",
    "            Can be either 'isotropic' or 'full'.\n",
    "        \"\"\"\n",
    "        self.n_states = n_states\n",
    "        self.n_pts = train_data.shape[0]\n",
    "        self.n_dims = train_data.shape[1]\n",
    "        self.train_data = train_data\n",
    "        self.cov_type = cov_type\n",
    "        self.trained = False\n",
    "        \n",
    "        #Initialization pi and cluster means using k-means\n",
    "        kmeans_init = K_Means(self.n_states, self.train_data, init=True)\n",
    "        self.z, self.mean = kmeans_init.train()\n",
    "        \n",
    "        self.pi = np.bincount(self.z) / self.n_pts\n",
    "        \n",
    "        #initialize as large spherical gaussian\n",
    "        self.cov = np.array([10 * np.eye(self.n_dims) \\\n",
    "                             for i in range(self.n_states)])\n",
    "\n",
    "    def train(self, n_iter=None):\n",
    "        \"\"\"\n",
    "        Training the algorithm until convergence of objective function\n",
    "        or for a certain number of iterations\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_iter : int (or None)\n",
    "            Number of iterations to train the K-means algorithm.\n",
    "            If it is None, we train the k-means algorithm\n",
    "            until convergence.  \n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        z : array-like, shape = [n_examples,n_classes]\n",
    "            array of onehot vectors indicating to which cluster each data\n",
    "            point is assigned\n",
    "        mean : array-like, shape = [n_classes,n_dims]\n",
    "            array containing the cluster mean for each class\n",
    "        \"\"\"\n",
    "        \n",
    "        old_val = 1e9\n",
    "        new_val = 1e8\n",
    "        \n",
    "        if n_iter is None:\n",
    "            while np.abs(old_val - new_val) > 0.0001:\n",
    "                #E step\n",
    "                #computing weights tau_i,j\n",
    "                self.weights = self._compute_weights(self.train_data)    \n",
    "\n",
    "                #M step\n",
    "                #updating pi, mean and covariance matrix\n",
    "                self._update_pi()\n",
    "                self._update_mean()\n",
    "                self._update_cov()\n",
    "\n",
    "                old_val = new_val\n",
    "                new_val = self._compute_objective()\n",
    "        else:\n",
    "            for i in range(n_iter):\n",
    "                #E step\n",
    "                #computing weights tau_i,j\n",
    "                self.weights = self._compute_weights(self.train_data)    \n",
    "\n",
    "                #M step\n",
    "                #updating pi, mean and covariance matrix\n",
    "                self._update_pi()\n",
    "                self._update_mean()\n",
    "                self._update_cov()                \n",
    "\n",
    "        self.trained = True\n",
    "\n",
    "    def show_clusters(self,iter):\n",
    "        if self.trained:\n",
    "            \"\"\"\n",
    "            Show data, cluster means and cluster assignments with ellipse representing 95.45%\n",
    "            of the mass of the Gaussian distribution for each cluster after training.\n",
    "            \"\"\"\n",
    "            f, ax = plt.subplots()\n",
    "            colors = ['r','g','b','y']\n",
    "            datalabels = np.argmax(self.weights, axis=1)\n",
    "            datacolor = []\n",
    "            for i in range(len(datalabels)):\n",
    "                datacolor.append(colors[datalabels[i]])\n",
    "            ax.scatter(self.train_data[:,0], self.train_data[:,1],marker='.', alpha=0.5,c=datacolor)\n",
    "            ax.scatter(self.mean[:,0], self.mean[:,1],marker='X',s=150,facecolor=colors, edgecolors='k',lw=2)\n",
    "            for j in range(self.n_states):\n",
    "                plot_cov_ellipse(self.cov[j], self.mean[j], ax=ax, alpha=0.2, color=colors[j])\n",
    "            ax.set_xlabel('feature 1')\n",
    "            ax.set_ylabel('feature 2')\n",
    "            if self.cov_type == 'isotropic':\n",
    "                ax.axis('equal')\n",
    "            ax.set_title('Final cluster means position')\n",
    "            plt.savefig('latex/figures/final_%s_%02d.png'%(self.cov_type,iter))\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "        else:\n",
    "            \"\"\"\n",
    "            Show data, cluster means and cluster assignments for each cluster after initialization\n",
    "            using k-means algorithm.\n",
    "            \"\"\"\n",
    "            colors = ['r','g','b','y']\n",
    "            datacolor = []\n",
    "            datalabels = np.argmax(self.z,axis=1)\n",
    "            for i in range(len(datalabels)):\n",
    "                datacolor.append(colors[datalabels[i]])\n",
    "            plt.scatter(self.train_data[:,0], self.train_data[:,1],marker='.', alpha=0.5,c=datacolor)\n",
    "            plt.scatter(self.mean[:,0], self.mean[:,1],marker='X',s=150,facecolor=colors, edgecolors='k',lw=2)\n",
    "            plt.xlabel('feature 1')\n",
    "            plt.ylabel('feature 2')\n",
    "            if self.cov_type == 'isotropic':\n",
    "                plt.axis('equal')\n",
    "            plt.title('Initial cluster means position')\n",
    "            plt.savefig('latex/figures/init_%s_%02d.png'%(self.cov_type,iter))\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            \n",
    "    def _compute_weights(self, data):\n",
    "        \"\"\"Computing weights of each class for each data point\"\"\"\n",
    "        numerator = np.zeros((len(data), self.n_states))\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(self.n_states):\n",
    "                numerator[i,j] = self.pi[j] * gaussian(data[i],\n",
    "                                                       self.mean[j],\n",
    "                                                       self.cov[j])\n",
    "        denominator = np.sum(numerator,axis=1)      \n",
    "        return np.divide(numerator.T,denominator).T\n",
    "    \n",
    "    def _update_pi(self):\n",
    "        \"\"\"Updating the parameter pi\"\"\"\n",
    "        self.pi = np.sum(self.weights,axis=0) / self.n_states\n",
    "            \n",
    "    def _update_mean(self):      \n",
    "        \"\"\"Updating the cluster means for each class\"\"\"\n",
    "        for j in range(self.n_states):\n",
    "            self.mean[j] = np.matmul(self.weights[:,j],self.train_data)\n",
    "        self.mean = np.divide(self.mean.T,np.sum(self.weights,axis=0)).T\n",
    "            \n",
    "    def _update_cov(self):\n",
    "        \"\"\"Updating the covariance matrix depending on the cov_type\"\"\"\n",
    "        if self.cov_type == 'isotropic':\n",
    "            self.cov = np.zeros_like(self.cov)\n",
    "            sigma = np.zeros(self.n_states)\n",
    "            for j in range(self.n_states):\n",
    "                for i in range(self.n_pts):\n",
    "                    sigma[j] += self.weights[i,j] * np.dot(self.train_data[i]-self.mean[j],\n",
    "                                                           self.train_data[i]-self.mean[j])\n",
    "            sigma = np.divide(sigma, self.n_dims * np.sum(self.weights, axis=0))\n",
    "            for j in range(self.n_states):\n",
    "                self.cov[j] = np.eye(self.n_dims)*sigma[j]\n",
    "        elif self.cov_type == 'full':\n",
    "            self.cov = np.zeros_like(self.cov)\n",
    "            for j in range(self.n_states):\n",
    "                for i in range(self.n_pts):\n",
    "                    self.cov[j] += self.weights[i,j] * np.outer(self.train_data[i]-self.mean[j],\n",
    "                                                                self.train_data[i]-self.mean[j])\n",
    "            norm = np.sum(self.weights, axis=0)\n",
    "            for j in range(self.n_states):\n",
    "                self.cov[j] /= norm[j]\n",
    "        else:\n",
    "            raise Exception('Type of covariance matrix not supported')\n",
    "            \n",
    "    def _compute_objective(self):\n",
    "        \"\"\"Computing the objective function used in k-means (for convergence of algorithm)\"\"\"\n",
    "        objective = 0\n",
    "        for i in range(self.n_pts):\n",
    "            objective += np.sum(np.abs(self.train_data[i] - np.matmul(self.weights[i],self.mean))**2)\n",
    "        return objective\n",
    "\n",
    "    def log_likelihood(self, data):\n",
    "        \"\"\"\n",
    "        Computing the normalized log-likelihood for a \n",
    "        given dataset using the learned parameters\n",
    "        \"\"\"\n",
    "        logl = 0\n",
    "        weights = self._compute_weights(data)\n",
    "        \n",
    "        self.pi = np.sum(self.weights,axis=0) / self.n_states\n",
    "        \n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(self.n_states):\n",
    "                #gaussian log likelihood\n",
    "                logl += weights[i,j] * np.log(gaussian(data[i], \n",
    "                                                       self.mean[j], \n",
    "                                                       self.cov[j]))\n",
    "                #multinoulli log-likelihood\n",
    "                logl += weights[i,j] * np.log(self.pi[j])\n",
    "                \n",
    "        return  logl / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    \"\"\"Implementation of the Hidden Markov Model\"\"\"\n",
    "    \n",
    "    def __init__(self, MEAN, COV, PI, TRANSIT_MATRIX):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        MEAN : array-like, shape = [n_states, n_dims]\n",
    "            Initial mean of for each possible state.\n",
    "        COV : array-like, shape = [n_states, n_dims, n_dims]\n",
    "            Initial covariance matrix for possible state.\n",
    "        PI : array-like, shape = [n_states]\n",
    "            Initial probability for each possible state.\n",
    "        TRANSIT_MATRIX : array-like, shape = [n_states, n_states]\n",
    "            Initial transition probability from one state to another.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_states = TRANSIT_MATRIX.shape[0]          #nb of states in the model\n",
    "        self.n_dims = MEAN.shape[1]\n",
    "        self.mean = MEAN\n",
    "        self.cov = COV\n",
    "        self.pi = PI\n",
    "        self.transit = TRANSIT_MATRIX\n",
    "        \n",
    "    def _forward(self, data):\n",
    "        \n",
    "        n_pts = data.shape[0]\n",
    "        \n",
    "        #initialize empty alpha array\n",
    "        self.alpha = np.zeros((n_pts, self.n_states))   \n",
    "\n",
    "        for t in range(n_pts):\n",
    "            for k in range(self.n_states):\n",
    "                if t == 0:\n",
    "                    # base case\n",
    "                    self.alpha[t,k] = self.pi[k] * gaussian(data[t], \n",
    "                                                           self.mean[k], \n",
    "                                                           self.cov[k])                    \n",
    "                else:\n",
    "                    self.alpha[t,k] = np.sum(self.alpha[t-1,:] * \\\n",
    "                                             self.transit[:,k] * \\\n",
    "                                             gaussian(data[t], self.mean[k], self.cov[k]))\n",
    "                    \n",
    "            #normalizing to solve the problem where the message vanishes to 0\n",
    "            self.alpha[t] /= np.sum(self.alpha[t])\n",
    "    \n",
    "    def _backward(self, data):\n",
    "        \n",
    "        n_pts = data.shape[0]\n",
    "        \n",
    "        #initialize empty beta array\n",
    "        self.beta = np.zeros((n_pts, self.n_states))\n",
    "\n",
    "        for t in reversed(range(n_pts)):\n",
    "            for k in range(self.n_states):\n",
    "                if t == (n_pts - 1):\n",
    "                    # base case\n",
    "                    self.beta[t,k] = 1\n",
    "                else:\n",
    "                    emission = np.array([gaussian(data[t+1], \n",
    "                                                  self.mean[i], \n",
    "                                                  self.cov[i]) for i in range(self.n_states)])\n",
    "                    \n",
    "                    self.beta[t,k] = np.sum(self.beta[t+1,:] * self.transit[k,:] * emission)\n",
    "                    \n",
    "            #normalizing to solve the problem where the message vanishes to 0\n",
    "            self.beta[t] /= np.sum(self.beta[t])    \n",
    "            \n",
    "    def _e_step(self, data):\n",
    "        \n",
    "        # E step\n",
    "        self._forward(data)\n",
    "        self._backward(data)\n",
    "        \n",
    "        n_pts = data.shape[0]\n",
    "       \n",
    "        #computing gamma\n",
    "        self.gamma = self.alpha * self.beta\n",
    "        self.gamma = np.divide(self.gamma.T, np.sum(self.gamma, axis=1)).T\n",
    "            \n",
    "        #computing xi\n",
    "        self.xi = np.zeros((n_pts-1, self.n_states, self.n_states))    #3rd degree tensor\n",
    "        \n",
    "        for t in range(1,n_pts):\n",
    "            for i in range(self.n_states):\n",
    "                for j in range(self.n_states):\n",
    "                    self.xi[t-1,i,j] = self.alpha[t-1,i] * \\\n",
    "                                       gaussian(data[t],self.mean[j],self.cov[j]) * \\\n",
    "                                       self.transit[i,j] * \\\n",
    "                                       self.beta[t,j]\n",
    "                #normalizing\n",
    "                self.xi[t-1,i] = np.divide(self.xi[t-1,i], np.sum(self.xi[t-1,i]))\n",
    "\n",
    "\n",
    "    def _m_step(self,data):\n",
    "        \n",
    "        # M step\n",
    "\n",
    "        n_pts = data.shape[0]\n",
    "                \n",
    "        # updating pi\n",
    "        self.pi = np.divide(self.gamma[0],np.sum(self.gamma[0]))\n",
    "        \n",
    "        # updating transition matrix A\n",
    "        self.transit = np.sum(self.xi, axis=0)\n",
    "        self.transit = np.divide(self.transit, np.sum(self.transit, axis=1))\n",
    "        \n",
    "        # updating mean of gaussians\n",
    "        self.mean = np.matmul(self.gamma.T, data)\n",
    "        self.mean = np.divide(self.mean.T, np.sum(self.gamma.T, axis=1)).T\n",
    "        \n",
    "        # updating covariance matrices\n",
    "        self.cov = np.zeros((4,2,2))\n",
    "\n",
    "        for k in range(self.n_states):\n",
    "            for t in range(n_pts):\n",
    "                self.cov[k] += self.gamma[t,k] * np.outer((data[t] - self.mean[k]),\n",
    "                                                          (data[t] - self.mean[k]))\n",
    "        norm = np.sum(self.gamma, axis=0)\n",
    "        for i in range(self.n_states):\n",
    "            self.cov[i] /= norm[i]\n",
    "            \n",
    "    def train(self, data, n_iter=None):\n",
    "        \n",
    "        if n_iter is None:\n",
    "\n",
    "            # initial values for convergence condition\n",
    "            old_val = 0\n",
    "            new_val = 10000\n",
    "\n",
    "            while np.abs(new_val - old_val) > 0.0001:\n",
    "                #training iteration using the EM algorithm\n",
    "                self._e_step(data)\n",
    "                self._m_step(data)\n",
    "\n",
    "                old_val = new_val\n",
    "                new_val = self.log_likelihood(data)\n",
    "\n",
    "        else:\n",
    "            for i in range(n_iter):\n",
    "                #training iteration using the EM algorithm\n",
    "                hmm._e_step(data)\n",
    "                hmm._m_step(data)\n",
    "    \n",
    "    def viterbi(self, data):\n",
    "        \n",
    "        n_pts = data.shape[0]\n",
    "        \n",
    "        path = np.zeros((n_pts, self.n_states)).astype('int')\n",
    "        scores = np.zeros((n_pts, self.n_states))\n",
    "        \n",
    "        for t in range(n_pts):\n",
    "            if t == 0:\n",
    "                #base case\n",
    "                for k in range(self.n_states):\n",
    "                    scores[t,k] = self.pi[k] * gaussian(data[t],\n",
    "                                               self.mean[k],\n",
    "                                               self.cov[k])\n",
    "                scores[t] /= np.sum(scores[t])\n",
    "            else:\n",
    "                #forward propagation\n",
    "                tmp = (scores[t-1] * self.transit.T).T\n",
    "                scores[t] = np.max(tmp, axis=0) * \\\n",
    "                            np.array([gaussian(data[t], \n",
    "                                               self.mean[k], \n",
    "                                               self.cov[k]) for k in range(self.n_states)])\n",
    "                path[t] = np.argmax(tmp, axis=0)\n",
    "                #normalizing\n",
    "                scores[t] /= np.sum(scores[t])\n",
    "        \n",
    "        #backtracking to find most likely sequence of states\n",
    "        seq = np.zeros(n_pts).astype('int')\n",
    "\n",
    "        for t in reversed(range(n_pts)):\n",
    "            if t == (n_pts - 1):\n",
    "                #base case\n",
    "                seq[t] = np.argmax(scores[t])\n",
    "            else:\n",
    "                seq[t] = path[t+1, seq[t+1]]\n",
    "        \n",
    "        return seq, scores\n",
    "\n",
    "    def log_likelihood(self, data):\n",
    "        \n",
    "        n_pts = data.shape[0]\n",
    "        \n",
    "        #initial configuration term\n",
    "        init = 0\n",
    "        for k in range(self.n_states):\n",
    "            init += self.gamma[0,k] * np.log(self.pi[k])\n",
    "            \n",
    "        #emission term\n",
    "        emission = 0\n",
    "        for t in range(n_pts):\n",
    "            for k in range(self.n_states):\n",
    "                emission += self.gamma[t,k] * np.log(gaussian(data[t], \n",
    "                                                              self.mean[k],\n",
    "                                                              self.cov[k]))\n",
    "        #transition term\n",
    "        transition = 0\n",
    "        sum_xi = np.sum(self.xi,axis=0)\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_states):\n",
    "                transition += np.log(self.transit[i,j]) * sum_xi[i,j]      \n",
    "        \n",
    "        #normalized log likelihood\n",
    "        logl = (init + emission + transition) / n_pts\n",
    "        \n",
    "        return logl\n",
    "    \n",
    "    def show_clusters(self, data):\n",
    "        \"\"\"\n",
    "        Show data, cluster means and cluster assignments with ellipse representing 95.45%\n",
    "        of the mass of the Gaussian distribution for each cluster after training.\n",
    "        \"\"\"\n",
    "        f, ax = plt.subplots()\n",
    "        colors = ['r','g','b','y']\n",
    "        datalabels = np.argmax(self.gamma, axis=1)\n",
    "        datacolor = []\n",
    "        for i in range(len(datalabels)):\n",
    "            datacolor.append(colors[datalabels[i]])\n",
    "        ax.scatter(data[:,0], data[:,1],marker='.', alpha=0.5,c=datacolor)\n",
    "        ax.scatter(self.mean[:,0], self.mean[:,1],marker='X',s=150,facecolor=colors, edgecolors='k',lw=2)\n",
    "        for j in range(self.K):\n",
    "            plot_cov_ellipse(self.cov[j], self.mean[j], ax=ax, alpha=0.2, color=colors[j])\n",
    "        ax.set_xlabel('feature 1')\n",
    "        ax.set_ylabel('feature 2')\n",
    "        ax.set_title('Final cluster means position')\n",
    "        #plt.savefig('latex/figures/final_%s_%02d.png'%(self.cov_type,iter))\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(data, mean, cov):\n",
    "    \"\"\"Computing gaussian probability given a data point, a mean and a covariance matrix\"\"\"\n",
    "    if type(data) == np.float64:\n",
    "        return (1/(2*np.pi*cov))**0.5 * \\\n",
    "            np.exp(-0.5 * (data-mean)*(1/cov)*(data-mean))\n",
    "    else:\n",
    "        return (1/np.linalg.det(2*np.pi*cov))**0.5 * \\\n",
    "            np.exp(-0.5 * np.dot(np.matmul((data-mean),np.linalg.inv(cov)),(data-mean)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cov_ellipse(cov, pos, nstd=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plotting an ellipse representing a percentage of the mass of the Gaussian distribution.\n",
    "    Taken from stackoverflow:\n",
    "    https://stackoverflow.com/questions/12301071/multidimensional-confidence-intervals\n",
    "    \"\"\"\n",
    "\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    vals, vecs = eigsorted(cov)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "\n",
    "    # Width and height are \"full\" widths, not radius\n",
    "    width, height = 2 * nstd * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=pos, width=width, height=height, angle=theta, **kwargs)\n",
    "\n",
    "    ax.add_artist(ellip)\n",
    "    return ellip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fake_parameters_inference(data, plot=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points with which the HMM is trained.\n",
    "    plot : boolean\n",
    "        Decides whether or not a plot is created.\n",
    "    \"\"\"\n",
    "    \n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    hmm._e_step(data)\n",
    "\n",
    "    if plot:\n",
    "        plot_data_prob_by_state(hmm.gamma, 'fake_param_inference')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_log_likelihood(train_data, test_data, n_iter=None, plot=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points with which the HMM is trained.\n",
    "    test_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points for which we test the HMM after\n",
    "        training.\n",
    "    niter : int (or None)\n",
    "        Number of iterations to train the HMM.\n",
    "        If it is None, we train the HMM until convergence.\n",
    "    plot : boolean\n",
    "        Decides whether or not a plot is created.\n",
    "    \"\"\"\n",
    "    \n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    \n",
    "    if n_iter is None:\n",
    "        \n",
    "        # initial values for convergence condition\n",
    "        old_val = 0\n",
    "        new_val = 10000\n",
    "        \n",
    "        #initializing empty array to host log likelihood values\n",
    "        logl_train = np.array([])\n",
    "        logl_test = np.array([])\n",
    "        \n",
    "        while np.abs(new_val - old_val) > 0.0001:\n",
    "            #training iteration using the EM algorithm\n",
    "            hmm._e_step(train_data)\n",
    "            hmm._m_step(train_data)\n",
    "            \n",
    "            tmp = hmm.log_likelihood(train_data)\n",
    "            old_val = new_val\n",
    "            new_val = tmp\n",
    "            logl_train = np.append(logl_train, np.array([tmp]))\n",
    "\n",
    "            hmm._e_step(test_data)\n",
    "            tmp = hmm.log_likelihood(test_data)\n",
    "            logl_test = np.append(logl_test, np.array([tmp]))\n",
    "    else:\n",
    "        #initializing empty array to host log likelihood values\n",
    "        logl_train = np.zeros(niter)\n",
    "        logl_test = np.zeros(niter)\n",
    "        for i in range(n_iter):\n",
    "            #training iteration using the EM algorithm\n",
    "            hmm._e_step(train_data)\n",
    "            hmm._m_step(train_data)\n",
    "            logl_train[i] = hmm.log_likelihood(train_data)\n",
    "\n",
    "            hmm._e_step(test_data)\n",
    "            logl_test[i] = hmm.log_likelihood(test_data)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(logl_train, label='training data')\n",
    "        plt.plot(logl_test, label='test data')\n",
    "        plt.xlabel(\"Number of training iterations\")\n",
    "        plt.ylabel(\"Log likelihood\")\n",
    "        plt.legend(fancybox=True, shadow=True)\n",
    "        plt.savefig(\"latex/figures/log_likelihood_hmm.png\")\n",
    "        plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_table_log_likelihood(train_data, test_data, n_iter=None, table=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points with which the model is trained.\n",
    "    test_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points for which we test the model after\n",
    "        training.\n",
    "    niter : int (or None)\n",
    "        Number of iterations to train the HMM.\n",
    "        If it is None, we train the HMM until convergence.\n",
    "    table : boolean\n",
    "        Decides whether or not a table is created.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_states = TRANSIT_MATRIX.shape[0]\n",
    "    n_dims = train_data.shape[1]\n",
    "\n",
    "    logl_table = np.zeros((4,2))\n",
    "    \n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    hmm.train(train_data, n_iter)\n",
    "    logl_table[0,0] = hmm.log_likelihood(train_data)\n",
    "    hmm._e_step(test_data)\n",
    "    logl_table[0,1] = hmm.log_likelihood(test_data)\n",
    "    \n",
    "    gmm_full = GMM(n_states, train_data, 'full')\n",
    "    gmm_full.train(n_iter)\n",
    "    logl_table[1,0] = gmm_full.log_likelihood(train_data)\n",
    "    logl_table[1,1] = gmm_full.log_likelihood(test_data)\n",
    "    \n",
    "    gmm_iso = GMM(n_states, train_data, 'isotropic')\n",
    "    gmm_iso.train(n_iter)\n",
    "    logl_table[2,0] = gmm_iso.log_likelihood(train_data)\n",
    "    logl_table[2,1] = gmm_iso.log_likelihood(test_data)\n",
    "\n",
    "    k_means = K_Means(n_states, train_data)\n",
    "    k_means.train(n_iter)\n",
    "    logl_table[3,0] = k_means.log_likelihood(train_data)\n",
    "    logl_table[3,1] = k_means.log_likelihood(test_data)\n",
    "    \n",
    "    if table:\n",
    "        np.savetxt('latex/logl_table.csv', logl_table, delimiter=' & ', \n",
    "                   fmt='%2.2e', newline=' \\\\\\\\\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_plot_data(data, plot=False):\n",
    "    \n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    hmm.train(data)\n",
    "    \n",
    "    seq, scores = hmm.viterbi(data)\n",
    "    \n",
    "    if plot:\n",
    "        \"\"\"\n",
    "        Show data, cluster means and cluster assignments for each cluster after assignment\n",
    "        using the Viterbi algorithm.\n",
    "        \"\"\"\n",
    "        colors = ['r','g','b','y']\n",
    "        datacolor = []\n",
    "        datalabels = seq\n",
    "        for i in range(len(datalabels)):\n",
    "            datacolor.append(colors[datalabels[i]])\n",
    "        plt.scatter(data[:,0], data[:,1],marker='.', alpha=0.5,c=datacolor)\n",
    "        plt.scatter(hmm.mean[:,0], hmm.mean[:,1],marker='X',s=150,facecolor=colors, edgecolors='k',lw=2)\n",
    "        plt.xlabel('feature 1')\n",
    "        plt.ylabel('feature 2')\n",
    "        plt.savefig('latex/figures/viterbi_2d.png')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_parameters_inference(train_data, test_data, plot=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points with which the HMM is trained.\n",
    "    test_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points for which we test the HMM after\n",
    "        training.\n",
    "    plot : boolean\n",
    "        Decides whether or not a plot is created.\n",
    "    \"\"\"\n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    #learning parameters\n",
    "    hmm.train(train_data)\n",
    "    \n",
    "    hmm._e_step(test_data)\n",
    "    \n",
    "    z = np.zeros_like(hmm.gamma)\n",
    "    for i in range(z.shape[0]):\n",
    "        for j in range(z.shape[1]):\n",
    "            if hmm.gamma[i,j] == max(hmm.gamma[i]):\n",
    "                z[i,j] = 1\n",
    "            else:\n",
    "                z[i,j] = 0\n",
    "\n",
    "    if plot:\n",
    "        plot_data_prob_by_state(hmm.gamma, 'real_param_inference')\n",
    "        plot_data_prob_by_state(z, 'real_param_choice')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_ml_sequence_plot(train_data, test_data, plot=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points with which the HMM is trained.\n",
    "    test_data : array-like, shape = [n_pts, n_dims]\n",
    "        Data points for which we test the HMM after\n",
    "        training.\n",
    "    plot : boolean\n",
    "        Decides whether or not a plot is created.\n",
    "    \"\"\"\n",
    "    hmm = HMM(MEAN, COV, PI, TRANSIT_MATRIX)\n",
    "    #learning parameters\n",
    "    hmm.train(train_data)\n",
    "    \n",
    "    seq, scores = hmm.viterbi(test_data)\n",
    "\n",
    "    z = np.zeros((test_data.shape[0],TRANSIT_MATRIX.shape[0]))\n",
    "    for t in range(z.shape[0]):\n",
    "        z[t, seq[t]] = 1\n",
    "    \n",
    "    if plot:\n",
    "        plot_data_prob_by_state(z, 'real_param_viterbi')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_prob_by_state(data, figname):\n",
    "    # Four subplots sharing both x/y axes\n",
    "    dom = np.arange(100)\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(4, sharex=True, sharey=True,\n",
    "                                           figsize=(20, 10))\n",
    "\n",
    "    #setting colors of bars (from 0 (red) to 1 (green))\n",
    "    colors0 = cm.RdYlGn(data[:,0])\n",
    "    colors1 = cm.RdYlGn(data[:,1])\n",
    "    colors2 = cm.RdYlGn(data[:,2])\n",
    "    colors3 = cm.RdYlGn(data[:,3])\n",
    "\n",
    "    #making bar graphs for each state\n",
    "    ax1.bar(dom, data[:100,0], color=colors0)\n",
    "    ax2.bar(dom, data[:100,1], color=colors1)\n",
    "    ax3.bar(dom, data[:100,2], color=colors2)\n",
    "    ax4.bar(dom, data[:100,3], color=colors3)\n",
    "    # Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "    # all but bottom plot.\n",
    "    f.subplots_adjust(hspace=0.1)\n",
    "    plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)\n",
    "\n",
    "    #trick to show axes titles\n",
    "    f.text(0.5, 0.08, 't', ha='center', fontsize=15)\n",
    "    f.text(0.08, 0.5, 'Probability for each state', va='center',\n",
    "           rotation='vertical', fontsize=20)\n",
    "\n",
    "    plt.savefig('latex/figures/%s.png'%figname)\n",
    "    plt.show()\n",
    "    plt.clf()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJ/JkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11aa97d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118eeb278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Loading datasets\n",
    "    train_data = np.loadtxt('hwk4data/EMGaussian.train')\n",
    "    test_data = np.loadtxt('hwk4data/EMGaussian.test')\n",
    "    \n",
    "    # Number 2\n",
    "    #fake_parameters_inference(test_data, plot=True)\n",
    "    \n",
    "    # Number 5\n",
    "    #show_log_likelihood(train_data, test_data, plot=True)\n",
    "    \n",
    "    # Number 6\n",
    "    #make_table_log_likelihood(train_data, test_data, table=True)\n",
    "    \n",
    "    # Number 8\n",
    "    viterbi_plot_data(train_data, plot=True)\n",
    "    \n",
    "    # Numbers 9 & 10\n",
    "    #real_parameters_inference(train_data, test_data, plot=True)\n",
    "    \n",
    "    # Number 10\n",
    "    #viterbi_ml_sequence_plot(train_data, test_data, plot=True)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
